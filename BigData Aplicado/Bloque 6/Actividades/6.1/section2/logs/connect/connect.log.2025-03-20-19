[2025-03-20 19:01:37,026] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-03-20 19:01:37,031] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-124.04.1
	jvm.classpath = /home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/activation-1.1.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/argparse4j-0.7.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/audience-annotations-0.12.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/caffeine-2.9.3.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/checker-qual-3.19.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-beanutils-1.9.4.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-cli-1.4.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-collections-3.2.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-digester-2.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-io-2.14.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-lang3-3.12.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-logging-1.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/commons-validator-1.7.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/connect-api-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/connect-json-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/connect-mirror-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/connect-mirror-client-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/connect-runtime-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/connect-transforms-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/error_prone_annotations-2.10.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/hk2-api-2.6.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/hk2-locator-2.6.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/hk2-utils-2.6.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-annotations-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-core-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-databind-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jakarta.inject-2.6.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/javassist-3.29.2-GA.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/javax.activation-api-1.2.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/javax.annotation-api-1.3.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/javax.servlet-api-3.1.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jaxb-api-2.3.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jersey-client-2.39.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jersey-common-2.39.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jersey-hk2-2.39.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jersey-server-2.39.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jline-3.25.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jopt-simple-5.0.4.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jose4j-0.9.4.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/jsr305-3.0.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka_2.13-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-clients-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-metadata-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-raft-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-server-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-server-common-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-shell-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-storage-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-storage-api-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-streams-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-tools-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-tools-api-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/lz4-java-1.8.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/maven-artifact-3.9.6.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/metrics-core-2.2.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/metrics-core-4.1.12.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/mysql-connector-j-9.2.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-codec-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-common-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-handler-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-transport-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/paranamer-2.8.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/pcollections-4.0.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/plexus-utils-3.5.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/protobuf-java-3.25.5.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/reflections-0.10.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/reload4j-1.2.25.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/rocksdbjni-7.9.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/scala-library-2.13.14.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/scala-reflect-2.13.14.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/slf4j-api-1.7.36.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/snappy-java-1.1.10.5.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/swagger-annotations-2.2.8.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/trogdor-3.8.1.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/zookeeper-3.8.4.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/zookeeper-jute-3.8.4.jar:/home/carlos/Downloads/kafka_2.13-3.8.1/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, amd64, 6.11.0-19-generic
	os.vcpus = 6
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-03-20 19:01:37,032] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-03-20 19:01:37,064] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:37,289] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:37,297] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.1.zip (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:37,315] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.1.zip} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:37,316] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluent (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:37,351] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluent/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:37,548] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:37,556] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:37,557] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:37,566] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:37,567] INFO Scanning plugins with ServiceLoaderScanner took 504 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-20 19:01:37,568] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:37,641] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/libs/connect-file-3.8.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:37,642] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.1.zip (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:37,645] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluentinc-kafka-connect-jdbc-10.8.1.zip} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:37,646] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluent (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:38,220] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluent/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:38,229] INFO Loading plugin from: /home/carlos/Downloads/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:38,248] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:38,249] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-03-20 19:01:39,552] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-03-20 19:01:39,553] INFO Scanning plugins with ReflectionScanner took 1985 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-03-20 19:01:39,557] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluent/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.8.1
file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/confluent/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.8.1
file:/home/carlos/Downloads/kafka_2.13-3.8.1/plugins/kafka-connect-bluesky-source-0.0.1-jar-with-dependencies.jar	uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector	source	0.0.1
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-03-20 19:01:39,559] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,559] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,559] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,559] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,559] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,560] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,561] INFO Added plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,562] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,562] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,562] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,562] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,562] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,562] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,562] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,563] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,564] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,565] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,565] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,565] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,565] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,565] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,565] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,565] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-03-20 19:01:39,568] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,568] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,569] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'BlueskySourceConnector' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,570] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,571] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,572] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,573] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,573] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,573] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,573] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,573] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,573] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,573] INFO Added alias 'BlueskySource' to plugin 'uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,574] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,575] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,575] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,575] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-03-20 19:01:39,616] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [libs/connect-file-3.8.1.jar, /home/carlos/Downloads/kafka_2.13-3.8.1/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-03-20 19:01:39,617] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-03-20 19:01:39,620] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-20 19:01:39,674] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-20 19:01:39,675] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:39,675] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:39,675] INFO Kafka startTimeMs: 1742493699674 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:39,956] INFO Kafka cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-03-20 19:01:39,957] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-20 19:01:39,966] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-20 19:01:39,966] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-20 19:01:39,966] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-20 19:01:39,973] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-03-20 19:01:39,982] INFO Logging initialized @3437ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-03-20 19:01:40,014] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-03-20 19:01:40,014] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-03-20 19:01:40,042] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-124.04.1 (org.eclipse.jetty.server.Server:375)
[2025-03-20 19:01:40,070] INFO Started http_8083@2299d903{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-03-20 19:01:40,071] INFO Started @3526ms (org.eclipse.jetty.server.Server:415)
[2025-03-20 19:01:40,092] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-20 19:01:40,092] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-03-20 19:01:40,092] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-20 19:01:40,092] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-03-20 19:01:40,093] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-20 19:01:40,093] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-03-20 19:01:40,097] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-20 19:01:40,122] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,123] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,123] INFO Kafka startTimeMs: 1742493700122 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,129] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-20 19:01:40,129] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-20 19:01:40,145] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-03-20 19:01:40,172] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,172] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,172] INFO Kafka startTimeMs: 1742493700172 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,175] INFO Kafka Connect worker initialization took 3146ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-03-20 19:01:40,175] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-03-20 19:01:40,177] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-03-20 19:01:40,178] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-03-20 19:01:40,180] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-03-20 19:01:40,180] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-03-20 19:01:40,180] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-20 19:01:40,181] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-03-20 19:01:40,186] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-03-20 19:01:40,186] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,186] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,186] INFO Kafka startTimeMs: 1742493700186 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,214] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-03-20 19:01:40,260] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-03-20 19:01:40,261] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-03-20 19:01:40,262] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2025-03-20 19:01:40,264] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-20 19:01:40,293] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:01:40,324] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-20 19:01:40,325] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,325] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,325] INFO Kafka startTimeMs: 1742493700325 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,332] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-20 19:01:40,344] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:01:40,349] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:01:40,395] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-20 19:01:40,395] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,396] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,396] INFO Kafka startTimeMs: 1742493700395 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,412] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:01:40,424] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-20 19:01:40,427] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,427] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,428] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,429] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,496] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,497] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,497] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,498] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,498] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,498] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,498] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,498] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,499] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,499] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,499] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,499] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,499] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,500] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,501] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,618] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-20 19:01:40,619] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-20 19:01:40,619] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-03-20 19:01:40,620] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-03-20 19:01:40,620] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-20 19:01:40,642] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-20 19:01:40,643] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:01:40,648] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-20 19:01:40,648] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,649] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,649] INFO Kafka startTimeMs: 1742493700648 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,650] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-20 19:01:40,652] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:01:40,656] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:01:40,661] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-20 19:01:40,662] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,662] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,662] INFO Kafka startTimeMs: 1742493700662 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,671] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:01:40,674] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-20 19:01:40,674] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,674] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,674] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,675] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,675] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,694] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,694] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,694] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,695] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,695] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,721] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-20 19:01:40,721] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-20 19:01:40,725] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-03-20 19:01:40,726] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-03-20 19:01:40,736] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-20 19:01:40,737] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:01:40,741] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-20 19:01:40,741] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,741] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,741] INFO Kafka startTimeMs: 1742493700741 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,742] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-20 19:01:40,742] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:01:40,745] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-20 19:01:40,746] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:01:40,746] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:01:40,746] INFO Kafka startTimeMs: 1742493700746 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:01:40,755] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:01:40,757] INFO [Producer clientId=connect-cluster-configs] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:01:40,758] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-03-20 19:01:40,758] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-03-20 19:01:40,777] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:01:40,790] INFO Successfully processed removal of connector 'bluesky-AI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-20 19:01:40,791] INFO Successfully processed removal of connector 'bluesky-AI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-20 19:01:40,798] INFO Successfully processed removal of connector 'mysql-sink-bluesky' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-20 19:01:40,799] INFO Successfully processed removal of connector 'mysql-sink-bluesky' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-20 19:01:40,799] INFO Successfully processed removal of connector 'bluesky-AI' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-03-20 19:01:40,804] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-03-20 19:01:40,804] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-03-20 19:01:40,804] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-03-20 19:01:40,804] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-03-20 19:01:40,818] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:01:40,821] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator carlos-desktop:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-03-20 19:01:40,823] INFO Started o.e.j.s.ServletContextHandler@70f98f7a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-03-20 19:01:40,823] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-20 19:01:40,823] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-03-20 19:01:40,823] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-03-20 19:01:40,823] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:01:40,848] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:01:40,859] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=25, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-20 19:01:40,907] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=25, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-20 19:01:40,907] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 25 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', leaderUrl='http://127.0.1.1:8083/', offset=49, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-20 19:01:40,908] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1791)
[2025-03-20 19:01:40,908] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 49, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1864)
[2025-03-20 19:01:40,913] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 49 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1891)
[2025-03-20 19:01:40,913] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 49 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-20 19:01:40,913] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-20 19:02:13,451] INFO [0:0:0:0:0:0:0:1] - - [20/Mar/2025:18:02:13 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "curl/8.5.0" 69 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-20 19:03:18,713] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-20 19:03:18,749] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector bluesky-AI config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-03-20 19:03:18,756] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-20 19:03:18,756] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:03:18,763] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=26, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-20 19:03:18,775] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=26, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-20 19:03:18,775] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 26 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', leaderUrl='http://127.0.1.1:8083/', offset=50, connectorIds=[bluesky-AI], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-20 19:03:18,775] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 50 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-20 19:03:18,777] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector bluesky-AI (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-20 19:03:18,779] INFO [bluesky-AI|worker] Creating connector bluesky-AI of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-20 19:03:18,780] INFO [bluesky-AI|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-20 19:03:18,781] INFO [0:0:0:0:0:0:0:1] - - [20/Mar/2025:18:03:18 +0000] "POST /connectors HTTP/1.1" 201 1484 "-" "curl/8.5.0" 127 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-20 19:03:18,782] INFO [bluesky-AI|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:18,787] INFO [bluesky-AI|worker] Instantiated connector bluesky-AI with version 0.0.1 of type class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-20 19:03:18,788] INFO [bluesky-AI|worker] Finished creating connector bluesky-AI (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-20 19:03:18,789] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-20 19:03:18,790] INFO [bluesky-AI|worker] Starting connector {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=charlymech.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=eupu-5yt5-vku7-6ouw, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_ai, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-AI, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=ArtificialIntelligence, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector:50)
[2025-03-20 19:03:18,801] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-20 19:03:18,804] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:18,826] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Tasks [bluesky-AI-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-03-20 19:03:18,827] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-20 19:03:18,827] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:03:18,830] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=27, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-20 19:03:18,837] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=27, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-20 19:03:18,837] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 27 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', leaderUrl='http://127.0.1.1:8083/', offset=52, connectorIds=[bluesky-AI], taskIds=[bluesky-AI-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-20 19:03:18,838] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 52 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-20 19:03:18,839] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task bluesky-AI-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-20 19:03:18,842] INFO [bluesky-AI|task-0] Creating task bluesky-AI-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-20 19:03:18,843] INFO [bluesky-AI|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-20 19:03:18,845] INFO [bluesky-AI|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:18,845] INFO [bluesky-AI|task-0] TaskConfig values: 
	task.class = class uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-20 19:03:18,846] INFO [bluesky-AI|task-0] Instantiated task bluesky-AI-0 with version 0.0.1 of type uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-20 19:03:18,846] INFO [bluesky-AI|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-20 19:03:18,847] INFO [bluesky-AI|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-20 19:03:18,847] INFO [bluesky-AI|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task bluesky-AI-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-20 19:03:18,847] INFO [bluesky-AI|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task bluesky-AI-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-20 19:03:18,847] INFO [bluesky-AI|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task bluesky-AI-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-20 19:03:18,851] INFO [bluesky-AI|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.Flatten$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value, org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-20 19:03:18,852] INFO [bluesky-AI|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-20 19:03:18,854] INFO [bluesky-AI|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = bluesky-AI
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [dropLangs, flatten, renameUri, renameCid, renameHandle, renameDisplayName, renameAvatar]
	transforms.dropLangs.blacklist = null
	transforms.dropLangs.exclude = [langs]
	transforms.dropLangs.include = []
	transforms.dropLangs.negate = false
	transforms.dropLangs.predicate = null
	transforms.dropLangs.renames = []
	transforms.dropLangs.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.dropLangs.whitelist = null
	transforms.flatten.delimiter = .
	transforms.flatten.negate = false
	transforms.flatten.predicate = null
	transforms.flatten.type = class org.apache.kafka.connect.transforms.Flatten$Value
	transforms.renameAvatar.blacklist = null
	transforms.renameAvatar.exclude = []
	transforms.renameAvatar.include = []
	transforms.renameAvatar.negate = false
	transforms.renameAvatar.predicate = null
	transforms.renameAvatar.renames = [author.avatar:avatar]
	transforms.renameAvatar.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameAvatar.whitelist = null
	transforms.renameCid.blacklist = null
	transforms.renameCid.exclude = []
	transforms.renameCid.include = []
	transforms.renameCid.negate = false
	transforms.renameCid.predicate = null
	transforms.renameCid.renames = [id.cid:cid]
	transforms.renameCid.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameCid.whitelist = null
	transforms.renameDisplayName.blacklist = null
	transforms.renameDisplayName.exclude = []
	transforms.renameDisplayName.include = []
	transforms.renameDisplayName.negate = false
	transforms.renameDisplayName.predicate = null
	transforms.renameDisplayName.renames = [author.displayName:displayName]
	transforms.renameDisplayName.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameDisplayName.whitelist = null
	transforms.renameHandle.blacklist = null
	transforms.renameHandle.exclude = []
	transforms.renameHandle.include = []
	transforms.renameHandle.negate = false
	transforms.renameHandle.predicate = null
	transforms.renameHandle.renames = [author.handle:handle]
	transforms.renameHandle.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameHandle.whitelist = null
	transforms.renameUri.blacklist = null
	transforms.renameUri.exclude = []
	transforms.renameUri.include = []
	transforms.renameUri.negate = false
	transforms.renameUri.predicate = null
	transforms.renameUri.renames = [id.uri:uri]
	transforms.renameUri.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.renameUri.whitelist = null
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:18,855] INFO [bluesky-AI|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-bluesky-AI-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-20 19:03:18,856] INFO [bluesky-AI|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:03:18,859] INFO [bluesky-AI|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-20 19:03:18,860] INFO [bluesky-AI|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:03:18,860] INFO [bluesky-AI|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:03:18,860] INFO [bluesky-AI|task-0] Kafka startTimeMs: 1742493798860 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:03:18,865] INFO [bluesky-AI|task-0] [Producer clientId=connector-producer-bluesky-AI-0] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:03:18,870] INFO [bluesky-AI|task-0] Starting task {connector.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceConnector, bluesky.identity=charlymech.bsky.social, transforms.renameAvatar.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.dropLangs.exclude=langs, transforms.renameUri.renames=id.uri:uri, bluesky.password=eupu-5yt5-vku7-6ouw, transforms.flatten.type=org.apache.kafka.connect.transforms.Flatten$Value, tasks.max=1, transforms=dropLangs,flatten,renameUri,renameCid,renameHandle,renameDisplayName,renameAvatar, transforms.dropLangs.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameAvatar.renames=author.avatar:avatar, transforms.renameCid.renames=id.cid:cid, transforms.renameCid.type=org.apache.kafka.connect.transforms.ReplaceField$Value, transforms.renameUri.type=org.apache.kafka.connect.transforms.ReplaceField$Value, bluesky.topic=bluesky_ai, task.class=uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask, transforms.renameDisplayName.type=org.apache.kafka.connect.transforms.ReplaceField$Value, name=bluesky-AI, transforms.renameHandle.type=org.apache.kafka.connect.transforms.ReplaceField$Value, value.converter=org.apache.kafka.connect.json.JsonConverter, bluesky.searchterm=ArtificialIntelligence, transforms.renameHandle.renames=author.handle:handle, key.converter=org.apache.kafka.connect.storage.StringConverter, transforms.renameDisplayName.renames=author.displayName:displayName} (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskySourceTask:39)
[2025-03-20 19:03:18,870] INFO [bluesky-AI|task-0] AbstractConfig values: 
	bluesky.identity = charlymech.bsky.social
	bluesky.password = [hidden]
	bluesky.poll.ms = 60000
	bluesky.searchterm = ArtificialIntelligence
	bluesky.topic = bluesky_ai
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-20 19:03:18,870] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-20 19:03:18,881] INFO [bluesky-AI|task-0] Creating a Bluesky data fetcher (uk.co.dalelane.kafkaconnect.bluesky.source.BlueskyDataFetcher:87)
[2025-03-20 19:03:19,029] INFO [bluesky-AI|task-0] Logging into Bluesky as charlymech.bsky.social (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:112)
[2025-03-20 19:03:19,748] INFO [bluesky-AI|task-0] WorkerSourceTask{id=bluesky-AI-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-20 19:03:24,748] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-19T21:17:34.819Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:03:25,691] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T17:58:53.502Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:03:28,870] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 99 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:03:40,630] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-20 19:03:40,638] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector mysql-sink-bluesky config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-03-20 19:03:40,638] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-20 19:03:40,639] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:03:40,644] INFO [0:0:0:0:0:0:0:1] - - [20/Mar/2025:18:03:40 +0000] "POST /connectors HTTP/1.1" 201 790 "-" "curl/8.5.0" 38 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-20 19:03:40,645] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=28, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-20 19:03:40,651] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=28, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-20 19:03:40,651] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 28 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', leaderUrl='http://127.0.1.1:8083/', offset=53, connectorIds=[mysql-sink-bluesky, bluesky-AI], taskIds=[bluesky-AI-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-20 19:03:40,652] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 53 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-20 19:03:40,652] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-20 19:03:40,652] INFO [mysql-sink-bluesky|worker] Creating connector mysql-sink-bluesky of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-20 19:03:40,653] INFO [mysql-sink-bluesky|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_ai]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-20 19:03:40,657] INFO [mysql-sink-bluesky|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_ai]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:40,658] INFO [mysql-sink-bluesky|worker] Instantiated connector mysql-sink-bluesky with version 10.8.1 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-20 19:03:40,658] INFO [mysql-sink-bluesky|worker] Finished creating connector mysql-sink-bluesky (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-20 19:03:40,658] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-20 19:03:40,660] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_ai]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-20 19:03:40,661] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_ai]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:40,662] INFO [mysql-sink-bluesky|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-03-20 19:03:40,681] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Tasks [mysql-sink-bluesky-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-03-20 19:03:40,681] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-20 19:03:40,682] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:03:40,684] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=29, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-20 19:03:40,690] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=29, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-20 19:03:40,690] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 29 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', leaderUrl='http://127.0.1.1:8083/', offset=55, connectorIds=[mysql-sink-bluesky, bluesky-AI], taskIds=[mysql-sink-bluesky-0, bluesky-AI-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-20 19:03:40,690] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 55 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-20 19:03:40,691] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-20 19:03:40,696] INFO [mysql-sink-bluesky|task-0] Creating task mysql-sink-bluesky-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-20 19:03:40,697] INFO [mysql-sink-bluesky|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-20 19:03:40,698] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:40,699] INFO [mysql-sink-bluesky|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-20 19:03:40,699] INFO [mysql-sink-bluesky|task-0] Instantiated task mysql-sink-bluesky-0 with version 10.8.1 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-20 19:03:40,699] INFO [mysql-sink-bluesky|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2025-03-20 19:03:40,700] INFO [mysql-sink-bluesky|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-20 19:03:40,700] INFO [mysql-sink-bluesky|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:679)
[2025-03-20 19:03:40,700] INFO [mysql-sink-bluesky|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-sink-bluesky-0 using the connector config (org.apache.kafka.connect.runtime.Worker:685)
[2025-03-20 19:03:40,700] INFO [mysql-sink-bluesky|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-sink-bluesky-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-20 19:03:40,702] WARN [mysql-sink-bluesky|task-0] Configuration key whitelist is deprecated and may be removed in the future.  Please update your configuration to use include instead. (org.apache.kafka.common.utils.ConfigUtils:113)
[2025-03-20 19:03:40,702] INFO [mysql-sink-bluesky|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{org.apache.kafka.connect.transforms.ReplaceField$Value} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-20 19:03:40,703] INFO [mysql-sink-bluesky|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_ai]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-03-20 19:03:40,703] INFO [mysql-sink-bluesky|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mysql-sink-bluesky
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [bluesky_ai]
	topics.regex = 
	transforms = [ReplaceFieldNames]
	transforms.ReplaceFieldNames.blacklist = null
	transforms.ReplaceFieldNames.exclude = []
	transforms.ReplaceFieldNames.include = []
	transforms.ReplaceFieldNames.negate = false
	transforms.ReplaceFieldNames.predicate = null
	transforms.ReplaceFieldNames.renames = []
	transforms.ReplaceFieldNames.type = class org.apache.kafka.connect.transforms.ReplaceField$Value
	transforms.ReplaceFieldNames.whitelist = [uri, cid, text, createdAt, handle, displayName, avatar]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:03:40,704] INFO [mysql-sink-bluesky|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mysql-sink-bluesky-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mysql-sink-bluesky
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-03-20 19:03:40,705] INFO [mysql-sink-bluesky|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:03:40,711] INFO [mysql-sink-bluesky|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-03-20 19:03:40,711] INFO [mysql-sink-bluesky|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:03:40,711] INFO [mysql-sink-bluesky|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:03:40,712] INFO [mysql-sink-bluesky|task-0] Kafka startTimeMs: 1742493820711 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:03:40,717] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-20 19:03:40,718] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Subscribed to topic(s): bluesky_ai (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-03-20 19:03:40,718] INFO [mysql-sink-bluesky|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-03-20 19:03:40,719] INFO [mysql-sink-bluesky|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost/task6
	connection.user = root
	date.timezone = DB_TIMEZONE
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	jdbc.credentials.provider.class = class io.confluent.connect.jdbc.util.DefaultJdbcCredentialsProvider
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	replace.null.with.default = true
	retry.backoff.ms = 3000
	table.name.format = bluesky
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-03-20 19:03:40,721] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:03:40,721] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:40,721] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:40,724] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:40,724] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:40,726] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:03:40,727] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:03:40,727] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-03-20 19:03:40,728] INFO [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-03-20 19:03:40,739] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:03:40,739] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Discovered group coordinator carlos-desktop:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-03-20 19:03:40,740] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-20 19:03:40,750] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: need to re-join with the given member-id: connector-consumer-mysql-sink-bluesky-0-c3357691-71c3-4d6b-86bf-bbca815ec92a (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-20 19:03:40,751] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-03-20 19:03:40,758] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-c3357691-71c3-4d6b-86bf-bbca815ec92a', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-03-20 19:03:40,765] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Finished assignment for group at generation 1: {connector-consumer-mysql-sink-bluesky-0-c3357691-71c3-4d6b-86bf-bbca815ec92a=Assignment(partitions=[bluesky_ai-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-03-20 19:03:40,770] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mysql-sink-bluesky-0-c3357691-71c3-4d6b-86bf-bbca815ec92a', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-03-20 19:03:40,770] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Notifying assignor about the new Assignment(partitions=[bluesky_ai-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-03-20 19:03:40,771] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Adding newly assigned partitions: bluesky_ai-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-03-20 19:03:40,784] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Found no committed offset for partition bluesky_ai-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-03-20 19:03:40,790] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting offset for partition bluesky_ai-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[carlos-desktop:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-03-20 19:03:41,048] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:03:41,049] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:03:41,085] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:03:41,101] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:03:41,114] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:03:41,121] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:03:41,452] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:41,455] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:03:41,456] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:41,458] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:03:41,458] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:41,458] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:41,458] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:41,458] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:41,459] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:03:41,459] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:03:41,459] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:03:44,476] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:03:44,477] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:03:44,502] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:03:44,505] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:03:44,515] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:03:44,519] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:03:44,602] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:44,609] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:03:44,610] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:44,611] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:03:44,612] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:44,612] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:44,612] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:44,612] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:44,612] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:03:44,612] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:03:44,612] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:03:45,829] INFO [0:0:0:0:0:0:0:1] - - [20/Mar/2025:18:03:45 +0000] "GET /connectors HTTP/1.1" 200 35 "-" "curl/8.5.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-20 19:03:47,627] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:03:47,627] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:03:47,647] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:03:47,650] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:03:47,656] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:03:47,661] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:03:47,723] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:47,724] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:03:47,724] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:47,725] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:03:47,726] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:47,726] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:47,726] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:47,726] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:47,726] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:03:47,726] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:03:47,726] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:03:50,727] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:03:50,728] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:03:50,746] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:03:50,749] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:03:50,756] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:03:50,757] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:03:50,807] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:50,808] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:03:50,808] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:50,810] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:03:50,810] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:50,810] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:50,811] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:50,811] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:50,811] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:03:50,811] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:03:50,811] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:03:53,826] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:03:53,826] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:03:53,848] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:03:53,850] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:03:53,857] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:03:53,862] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:03:53,897] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:53,898] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:03:53,898] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:53,899] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:03:53,899] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:53,899] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:53,899] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:53,899] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:53,899] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:03:53,899] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:03:53,899] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:03:56,913] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:03:56,914] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:03:56,932] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:03:56,936] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:03:56,944] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:03:56,947] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:03:56,998] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:57,000] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:03:57,001] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:03:57,003] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:03:57,004] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:57,004] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:57,004] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:03:57,004] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:03:57,004] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:03:57,004] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:03:57,004] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:04:00,019] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:04:00,019] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:04:00,032] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:04:00,035] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:04:00,043] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:04:00,048] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:04:00,089] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:00,090] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:04:00,090] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:00,091] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:04:00,091] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:00,092] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:00,092] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:00,092] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:00,092] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:04:00,092] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:04:00,092] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:04:00,824] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:04:00,824] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:04:00,845] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:04:00,847] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:04:00,852] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:04:00,853] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:04:00,890] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:00,891] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:04:00,891] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:00,892] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:04:00,892] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:00,892] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:00,893] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:00,893] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:00,893] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:04:00,893] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:04:00,893] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:04:03,906] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:04:03,907] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:04:03,931] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:04:03,933] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:04:03,938] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:04:03,940] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:04:03,980] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:03,981] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:04:03,981] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:03,982] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:04:03,982] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:03,982] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:03,982] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:03,982] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:03,983] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:04:03,983] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:04:03,983] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:04:06,997] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:04:06,997] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:04:07,011] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:04:07,013] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:04:07,018] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:04:07,020] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:04:07,060] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:07,061] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:04:07,061] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:07,062] INFO [mysql-sink-bluesky|task-0] Initializing JDBC writer (io.confluent.connect.jdbc.sink.JdbcSinkTask:65)
[2025-03-20 19:04:07,062] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:07,062] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:07,062] INFO [mysql-sink-bluesky|task-0] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2025-03-20 19:04:07,062] INFO [mysql-sink-bluesky|task-0] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2025-03-20 19:04:07,063] INFO [mysql-sink-bluesky|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:72)
[2025-03-20 19:04:07,063] INFO [mysql-sink-bluesky|task-0] JDBC writer initialized (io.confluent.connect.jdbc.sink.JdbcSinkTask:74)
[2025-03-20 19:04:07,063] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:119)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:04:10,076] INFO [mysql-sink-bluesky|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:57)
[2025-03-20 19:04:10,076] INFO [mysql-sink-bluesky|task-0] Database connection established. (io.confluent.connect.jdbc.util.CachedConnectionProvider:64)
[2025-03-20 19:04:10,093] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for existence of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:602)
[2025-03-20 19:04:10,096] INFO [mysql-sink-bluesky|task-0] Using MySql dialect TABLE "task6"."bluesky" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:610)
[2025-03-20 19:04:10,104] INFO [mysql-sink-bluesky|task-0] Checking MySql dialect for type of TABLE "task6"."bluesky" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:897)
[2025-03-20 19:04:10,106] INFO [mysql-sink-bluesky|task-0] Setting metadata for table "task6"."bluesky" to Table{name='"task6"."bluesky"', type=TABLE columns=[Column{'createdAt', isPrimaryKey=false, allowsNull=false, sqlType=DATETIME}, Column{'text', isPrimaryKey=false, allowsNull=false, sqlType=TEXT}, Column{'cid', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'uri', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'avatar', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}, Column{'handle', isPrimaryKey=false, allowsNull=false, sqlType=VARCHAR}, Column{'displayName', isPrimaryKey=false, allowsNull=true, sqlType=VARCHAR}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2025-03-20 19:04:10,142] ERROR [mysql-sink-bluesky|task-0] Error during write operation. Attempting rollback. (io.confluent.connect.jdbc.sink.JdbcDbWriter:89)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:10,143] INFO [mysql-sink-bluesky|task-0] Successfully rolled back transaction (io.confluent.connect.jdbc.sink.JdbcDbWriter:92)
[2025-03-20 19:04:10,143] WARN [mysql-sink-bluesky|task-0] Write of 228 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:102)
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:214)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:885)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:466)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:858)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:198)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:188)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:108)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:77)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:90)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Field 'uri' doesn't have a default value
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:121)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:114)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:990)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1168)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchSerially(ClientPreparedStatement.java:864)
	... 19 more
[2025-03-20 19:04:10,144] ERROR [mysql-sink-bluesky|task-0] Failing task after exhausting retries; encountered 2 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:124)
[2025-03-20 19:04:10,144] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:133)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:04:10,144] ERROR [mysql-sink-bluesky|task-0] WorkerSinkTask{id=mysql-sink-bluesky-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:133)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Field 'uri' doesn't have a default value
java.sql.SQLException: Field 'uri' doesn't have a default value

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:167)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:112)
	... 12 more
[2025-03-20 19:04:10,145] INFO [mysql-sink-bluesky|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:178)
[2025-03-20 19:04:10,149] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Revoke previously assigned partitions bluesky_ai-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-03-20 19:04:10,149] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] The pause flag in partitions [bluesky_ai-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-03-20 19:04:10,150] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Member connector-consumer-mysql-sink-bluesky-0-c3357691-71c3-4d6b-86bf-bbca815ec92a sending LeaveGroup request to coordinator carlos-desktop:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-03-20 19:04:10,151] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-03-20 19:04:10,151] INFO [mysql-sink-bluesky|task-0] [Consumer clientId=connector-consumer-mysql-sink-bluesky-0, groupId=connect-mysql-sink-bluesky] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-03-20 19:04:10,169] INFO [mysql-sink-bluesky|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-03-20 19:04:10,169] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-20 19:04:10,170] INFO [mysql-sink-bluesky|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-03-20 19:04:10,170] INFO [mysql-sink-bluesky|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-03-20 19:04:10,175] INFO [mysql-sink-bluesky|task-0] App info kafka.consumer for connector-consumer-mysql-sink-bluesky-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-03-20 19:04:24,748] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T17:58:53.502Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:04:25,415] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:03:24.513Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:04:28,887] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:05:24,748] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:03:24.513Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:05:25,133] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:04:40.260Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:05:28,892] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:06:24,748] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:04:40.260Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:06:25,304] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:06:28,896] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:06:40,260] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:07:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:08:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:09:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:10:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:10:40,481] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:10:40,512] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:10:40,830] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:10:40,854] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:10:40,981] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:10:41,074] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:10:41,126] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:11:20,987] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2483)
[2025-03-20 19:11:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:12:19,054] INFO [bluesky-AI|task-0] [Producer clientId=connector-producer-bluesky-AI-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:12:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:13:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:14:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:15:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:16:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:16:40,295] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:17:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:18:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:19:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:20:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:05:19.197Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:20:25,378] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:19:22.694Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:20:28,921] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:20:40,447] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:20:40,937] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:20:41,143] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:21:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:19:22.694Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:21:40,476] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:22:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:19:22.694Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:23:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:19:22.694Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:24:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:19:22.694Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:25:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:19:22.694Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:26:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:19:22.694Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:26:25,391] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:26:09.530985+00:00 (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:26:28,935] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:26:40,673] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:27:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:26:09.530985+00:00 (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:28:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:26:09.530985+00:00 (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:29:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:26:09.530985+00:00 (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:29:25,133] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:28:56.617Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:29:28,943] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:30:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:28:56.617Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:30:25,367] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:29:48.634Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:30:28,948] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:31:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:29:48.634Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:31:24,999] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:30:34.298Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:31:28,952] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 2 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:31:40,869] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:32:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:30:34.298Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:33:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:30:34.298Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:33:24,997] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:32:29.955Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:33:28,958] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:34:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:32:29.955Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:35:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:32:29.955Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:35:25,327] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:35:28,966] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:36:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:36:41,073] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:37:24,749] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:38:24,750] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:39:24,750] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:40:24,750] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:41:24,750] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:41:41,257] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:42:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:43:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:44:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:45:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:46:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:46:41,424] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:47:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:48:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:49:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:50:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:51:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:51:41,626] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-03-20 19:52:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:52:46,876] INFO [0:0:0:0:0:0:0:1] - - [20/Mar/2025:18:52:46 +0000] "GET /connectors HTTP/1.1" 200 35 "-" "curl/8.5.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-20 19:52:58,907] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-20 19:52:58,919] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector file-source-distributed config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-03-20 19:52:58,919] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-20 19:52:58,919] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:52:58,920] INFO [0:0:0:0:0:0:0:1] - - [20/Mar/2025:18:52:58 +0000] "POST /connectors HTTP/1.1" 201 240 "-" "curl/8.5.0" 16 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-20 19:52:58,921] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=30, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-20 19:52:58,924] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=30, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-20 19:52:58,924] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 30 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', leaderUrl='http://127.0.1.1:8083/', offset=57, connectorIds=[file-source-distributed, mysql-sink-bluesky, bluesky-AI], taskIds=[mysql-sink-bluesky-0, bluesky-AI-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-20 19:52:58,925] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 57 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-20 19:52:58,925] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector file-source-distributed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-03-20 19:52:58,925] INFO [file-source-distributed|worker] Creating connector file-source-distributed of type FileStreamSource (org.apache.kafka.connect.runtime.Worker:312)
[2025-03-20 19:52:58,926] INFO [file-source-distributed|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-20 19:52:58,926] INFO [file-source-distributed|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:52:58,926] INFO [file-source-distributed|worker] Instantiated connector file-source-distributed with version 3.8.1 of type class org.apache.kafka.connect.file.FileStreamSourceConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-03-20 19:52:58,927] INFO [file-source-distributed|worker] Finished creating connector file-source-distributed (org.apache.kafka.connect.runtime.Worker:355)
[2025-03-20 19:52:58,927] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-20 19:52:58,927] INFO [file-source-distributed|worker] AbstractConfig values: 
	batch.size = 2000
	file = /home/carlos/Downloads/kafka_2.13-3.8.1/section1.csv
	topic = section_1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-20 19:52:58,927] INFO [file-source-distributed|worker] Starting file source connector reading from /home/carlos/Downloads/kafka_2.13-3.8.1/section1.csv (org.apache.kafka.connect.file.FileStreamSourceConnector:69)
[2025-03-20 19:52:58,929] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-20 19:52:58,930] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:52:58,957] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Tasks [file-source-distributed-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-03-20 19:52:58,957] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-03-20 19:52:58,958] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-03-20 19:52:58,959] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=31, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-03-20 19:52:58,962] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=31, memberId='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-03-20 19:52:58,963] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 31 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-0c8a3024-3477-4f8a-9c70-7f66fcd3911d', leaderUrl='http://127.0.1.1:8083/', offset=59, connectorIds=[file-source-distributed, mysql-sink-bluesky, bluesky-AI], taskIds=[file-source-distributed-0, mysql-sink-bluesky-0, bluesky-AI-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-03-20 19:52:58,963] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 59 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-03-20 19:52:58,963] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting task file-source-distributed-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-03-20 19:52:58,964] INFO [file-source-distributed|task-0] Creating task file-source-distributed-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-03-20 19:52:58,964] INFO [file-source-distributed|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-03-20 19:52:58,964] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = file-source-distributed
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:52:58,967] INFO [file-source-distributed|task-0] TaskConfig values: 
	task.class = class org.apache.kafka.connect.file.FileStreamSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-03-20 19:52:58,967] INFO [file-source-distributed|task-0] Instantiated task file-source-distributed-0 with version 3.8.1 of type org.apache.kafka.connect.file.FileStreamSourceTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-03-20 19:52:58,967] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-20 19:52:58,968] INFO [file-source-distributed|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-03-20 19:52:58,968] INFO [file-source-distributed|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-03-20 19:52:58,968] INFO [file-source-distributed|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-03-20 19:52:58,968] INFO [file-source-distributed|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task file-source-distributed-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-03-20 19:52:58,969] INFO [file-source-distributed|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-03-20 19:52:58,969] INFO [file-source-distributed|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-03-20 19:52:58,969] INFO [file-source-distributed|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = FileStreamSource
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = file-source-distributed
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-03-20 19:52:58,970] INFO [file-source-distributed|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-file-source-distributed-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-03-20 19:52:58,970] INFO [file-source-distributed|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-03-20 19:52:58,976] INFO [file-source-distributed|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-03-20 19:52:58,976] INFO [file-source-distributed|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-03-20 19:52:58,977] INFO [file-source-distributed|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-03-20 19:52:58,977] INFO [file-source-distributed|task-0] Kafka startTimeMs: 1742496778976 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-03-20 19:52:58,979] INFO [file-source-distributed|task-0] AbstractConfig values: 
	batch.size = 2000
	file = /home/carlos/Downloads/kafka_2.13-3.8.1/section1.csv
	topic = section_1
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-03-20 19:52:58,979] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-03-20 19:52:58,980] INFO [file-source-distributed|task-0] WorkerSourceTask{id=file-source-distributed-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-03-20 19:52:58,992] INFO [file-source-distributed|task-0] [Producer clientId=connector-producer-file-source-distributed-0] Cluster ID: jVS0nPZPQGOqjEs5fW_ykA (org.apache.kafka.clients.Metadata:364)
[2025-03-20 19:53:06,072] INFO [0:0:0:0:0:0:0:1] - - [20/Mar/2025:18:53:06 +0000] "GET /connectors HTTP/1.1" 200 61 "-" "curl/8.5.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-03-20 19:53:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:34:19.035Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:53:25,146] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:52:39Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:53:28,996] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:54:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:52:39Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:54:58,982] INFO [file-source-distributed|task-0|offsets] WorkerSourceTask{id=file-source-distributed-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:55:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:52:39Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:56:24,751] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:52:39Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:56:58,987] INFO [file-source-distributed|task-0|offsets] WorkerSourceTask{id=file-source-distributed-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:57:24,752] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:52:39Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:58:24,752] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:52:39Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:58:25,380] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:58:15.398Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
[2025-03-20 19:58:29,008] INFO [bluesky-AI|task-0|offsets] WorkerSourceTask{id=bluesky-AI-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-03-20 19:59:24,752] INFO [bluesky-AI|task-0] Polling Bluesky for ArtificialIntelligence for posts using offset 2025-03-20T18:58:15.398Z (uk.co.dalelane.kafkaconnect.bluesky.api.BlueskyClient:208)
