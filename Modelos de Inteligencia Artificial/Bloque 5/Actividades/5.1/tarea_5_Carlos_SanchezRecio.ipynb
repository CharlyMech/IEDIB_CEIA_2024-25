{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tarea de esta entrega trabajará cuatro aplicaciones de procesamiento del lenguaje general: clasificación de texto, generación de texto, análisis sintáctico y recuperación de información (_Information Retrieval_) . \n",
    "\n",
    "Las funciones que necesitará las puede obtener del código del capítulo de NLP del libro AIMA. Deberá mirar qué dependencias tienen respecto a otros archivos, incluir el código que sea necesario o importarlo de otros módulos.\n",
    "\n",
    "[https://github.com/aimacode/aima-python/blob/master/nlp_apps.ipynb](https://github.com/aimacode/aima-python/blob/master/nlp_apps.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clasificación de texto según el autor\n",
    "\n",
    "Construya dos modelos de diferentes autores: Josep Carner y Miquel dels Sants Oliver. Para eso, puede usar sus obras disponibles en el Proyecto Gutenberg. Por ejemplo, de Carner tome la traducción de los cuentos de Mark Twain. Después, clasifica frases en el estilo de cada uno que muestren cómo su modelo las identifica correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aima_module.utils import open_data\n",
    "from aima_module.text import words, UnigramWordModel\n",
    "from aima_module.learning import NaiveBayesLearner\n",
    "\n",
    "def recognize_author(text, nbs):\n",
    "   return nbs(words(text.lower()))\n",
    "\n",
    "hostel = open_data('CA-Text/bolla_hostel.txt').read()\n",
    "wordseq_hostel = words(hostel)\n",
    "p_miquel = UnigramWordModel(wordseq_hostel, 5)\n",
    "\n",
    "adventures = open_data('CA-Text/tom_sawyer_adventures.txt').read()\n",
    "wordseq_adventures = words(adventures)\n",
    "p_josep = UnigramWordModel(wordseq_adventures, 5)\n",
    "\n",
    "\n",
    "nbs = NaiveBayesLearner({('Miquel', 1): p_miquel, ('Josep', 1): p_josep}, simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the \"L'hostal de la Bolla\" [line 172]\n",
    "recognize_author('de la familia, entre sacs de bessó i senalles de llegum. La botiga,', nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From \"The Adventures of Tom Sawyer\" [line 4149]\n",
    "recognize_author('resta de cent yardes. Nedava quartejant per amunt el corrent, però', nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Author's quotes prompt](./authors_phrases_prompt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Miquel dels Sants Oliver\n",
    "recognize_author('La joventut, en el sentit màgic, potser no ha mai existit i potser no és sinó un equador convencional entre la il·lusió i el record.', nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Josep Carner\n",
    "recognize_author('Una mica d\\'amistat fins a morir diu que dura. Vés, amor, metzina impura; vull la mel, vull el brossat d\\'una mica d\\'amistat.', nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como comentario a cerca del resultado, se puede observar que no es del todo preciso en la clasificación. Haciendo uso de la actividad de mi compañero David Ramírez ([enlace a su tarea](https://github.com/davidzz-code/IEDIB_2024_2025/blob/main/02%20Modelos%20IA/T5%20NLP/tarea_4_David_Ramirez_Ruiz.ipynb)), voy a probar con las frases que ha utilizado él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Miquel dels Sants Oliver\n",
    "recognize_author('Els carrers, encara humits, semblaven desertar de la nit', nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Josep Carner\n",
    "recognize_author('Amb un gest majestuós em fità un instant', nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que en este caso, el clasificador si que los diferencia correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generación de texto\n",
    "\n",
    "Construya modelos n-gram con n=1, n=3, n=5 y=7 a partir de un texto elegido por usted. Puede ser una obra del Proyecto Gutenberg o una noticia de prensa, por ejemplo. Observe como medida que aumenta el número de palabras que se han tenido en cuenta la verosimilitud del texto generado es mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram: 1\n",
      "solamente\n",
      "\n",
      "\n",
      "Ngram: 2\n",
      "eso viva mil insultos hac a hijo esteban mirad los dos jacinta apelo de suerte en lo averig e unless you within 30 2019 ebook for nearly all viene con cuidado buena para vuestros hombros flacos mirad los pa os laurencia all comendador as celoso de puro amor a refund set forth in formats readable form accessible by all vuestra gente el desear sale la quit is all en materia mengo as con leve causa se hiela barrildo es ya le merece y ya que habemos de tu consejo con paciencia y son extremadas laurencia bravo y antes un corcillo\n",
      "\n",
      "\n",
      "Ngram: 3\n",
      "24 madrid como tantas otras comedias de nuestro teatro la presente publicada en 1619 los par ntesis cuadrados indican que se trata de un viejo de palos das laurencia si le faltare alg n corzo esc ndete en esas ramas frondoso y laurencia laurencia se or es ste laurencia tirando viene a ser posible a la edad esteban qui resle t laurencia voluntad le he cobrado pero por lo que nos quit is el valor amor hay y principal de alguno que dan tormento oye con atento o do y son si yo mal no siento de alguno que dan\n",
      "\n",
      "\n",
      "Ngram: 4\n",
      "perdonar o matar la villa toda todos vienen ante ti para m s certificarte de ellos podr s informarte rey que entren pues vienen les di salen los dos alcaldes frondoso las mujeres y los villanos que quisieren laurencia aquestos los reyes son frondoso y en castilla poderosos laurencia por mi fe que son hermosos bend galos san ant n isabel los agresores son stos alcalde esteban fuente ovejuna lo ha hecho esteban quer is responder as todos s esteban ahora 43 pues yo quiero ser agora el pesquisidor para ensayarnos mejor en lo que ama da o espera aumenta\n",
      "\n",
      "\n",
      "Ngram: 5\n",
      "descortes a ortu o si supiese un descort s c mo lo aborrecen todos y querr an de mil modos poner la boca a sus pies antes que serlo ninguno se dejar a morir flores qu cansado es de sufrir qu spero y qu importuno llaman la descortes a necedad en los iguales porque es entre desiguales linaje de tiran a aqu no te toca nada que un muchacho aun no ha llegado a saber qu es ser amado comendador la obligaci n de la espada que se ci el mismo d a que la cruz de calatrava le cubri\n",
      "\n",
      "\n",
      "Ngram: 6\n",
      "sentimentales que le ofrec a el episodio narrado en la cr nica diversos chispazos heroicos van preparando el momento tr gico en que los habitantes de la villa sin flaquear gimen bajo las cuerdas de la tortura pero esta suprema belleza las m ltiples situaciones de inter s y el atractivo de los versos se manifestar n al lector sin necesidad de que el editor lo advierta para imprimir esta comedia se ha tenido en cuenta el texto de la parte xii de lope publicada en 1619 los par ntesis cuadrados indican que se a ade algo no se advierte\n",
      "\n",
      "\n",
      "Ngram: 7\n",
      "el se or las armas en las manos esteban el rey solo es se or despu s del cielo y no b rbaros hombres inhumanos si dios ayuda nuestro justo celo qu nos ha de costar mengo mirad se ores que vais en estas cosas con recelo puesto que 40 por los simples labradores estoy aqu que m s injurias pasan m s cuerdo represento sus temores 40 aunque juan si nuestras desventuras se compasan para perder las vidas qu aguardamos las casas y las vi as nos abrasan tiranos son a la venganza vamos sale laurencia desmelenada laurencia dejadme\n",
      "\n",
      "\n",
      "Ngram: 8\n",
      "se or el no haberle es cierto pues no escap ning n noble de preso herido o de muerto isabel ese caso no requiere ser despacio remediado que es dar al contrario osado el mismo valor que adquiere y puede el de portugal hallando puerta segura entrar por extremadura y causamos mucho mal rey don manrique partid luego llevando dos compa as remediad sus demas as sin darles ning n sosiego el conde de cabra ir puede con vos que es c rdoba osado a quien nombre de soldado todo el mundo le concede que ste es el medio mejor\n",
      "\n",
      "\n",
      "Ngram: 9\n",
      "para la redondilla pero no para el sentido frondoso bravo caso juez ese muchacho aprieta perro yo s que lo sabes di qui n fu callas aprieta borracho ni o fuente ovejuna se or juez por vida del rey villanos que os ahorque con mis manos qui n mat al comendador frondoso que a un ni o le den tormento y niegue de aquesta suerte laurencia bravo pueblo frondoso bravo y fuerte juez esa mujer al momento en ese potro tened dale esa mancuerda luego laurencia ya est de c lera ciego juez que os he de matar creed en\n",
      "\n",
      "\n",
      "Ngram: 10\n",
      "grande que en ellos crece que las mayores tajadas las orejas a ser vienen sus armas borran con picas y a voces dicen que quieren tus reales armas fijar porque aqu llas les ofenden saque ronle la casa cual si de enemigos fuese y gozosos entre todos han repartido sus bienes lo dicho he visto escondido porque mi infelice suerte en tal trance no permite que mi vida se perdiese y as estuve todo el d a hasta que la noche viene y salir pude escondido para que cuenta te diese haz se or pues eres justo que la justa\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "from aima_module.text import NgramWordModel, words\n",
    "\n",
    "def generate_text(model, length, ngram=5):\n",
    "\tgenerate = []\n",
    "\tseed = choice(list(model.dictionary.keys()))\n",
    "\tgenerate.extend(seed)\n",
    "\n",
    "\tfor i in range(length-ngram):\n",
    "\t\tlast = tuple(generate[-(ngram-1):])\n",
    "\t\tnext = []\n",
    "\n",
    "\t\tfor j in model.dictionary.keys():\n",
    "\t\t\tif j[:ngram-1] == last: next.append(j[ngram-1])\n",
    "\t\t\n",
    "\t\tif not next: break\n",
    "\n",
    "\t\tnext = choice(next)\n",
    "\t\tgenerate.append(next)\n",
    "\t\n",
    "\treturn ' '.join(generate)\n",
    "\n",
    "# In my case I decided to use the Spanish classic 'Fuenteovejuna' by Lope de Vega\n",
    "fuenteovejuna = open_data('ES-Text/fuente_ovejuna.txt').read()\n",
    "wordseq = words(fuenteovejuna)\n",
    "\n",
    "# I decided to automate the text generation process from 1 ngram to 10 ngrams and 100 words length\n",
    "for i in range(1, 11):\n",
    "\tmodel = NgramWordModel(i, wordseq)\n",
    "\tprint(f'Ngram: {i}\\n{generate_text(model=model, length=100, ngram=i)}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se esperaba, a medida que se aumentan los _n-gram_ los textos son más coherentes, aunque se pueden ver ciertos casos como en el **ngram=8** que no es perfecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análisis sintáctico\n",
    "\n",
    "Aplica las herramientas de alguna librería Python para analizar sintácticamente la siguiente oración:\n",
    "\n",
    "- (ES): _Todos los seres humanos nacen libres e iguales en dignidad y derechos._\n",
    "\n",
    "- (CA): _Tots els éssers humans neixen lliures i iguals en dignitat i drets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_sm-3.8.0/ca_core_news_sm-3.8.0-py3-none-any.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ca_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ca_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "es_nlp = spacy.load('es_core_news_sm')\n",
    "ca_nlp = spacy.load('ca_core_news_sm')\n",
    "\n",
    "es_sentence = 'Todos los seres humanos nacen libres e iguales en dignidad y derechos'\n",
    "ca_sentence = 'Tots els éssers humans neixen lliures i iguals en dignitat i drets'\n",
    "\n",
    "es_doc = es_nlp(es_sentence)\n",
    "ca_doc = ca_nlp(ca_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- CATALAN Syntax -\n",
      "Noun Phrases: ['Tots els éssers humans', 'dignitat i drets']\n",
      "Verbs: ['neixar']\n",
      "Subjects: ['éssers']\n",
      "Adjectives: ['humans', 'lliures', 'iguals']\n",
      "Prepositions: ['en']\n",
      "Conjunctions: ['i', 'i']\n",
      "+ Each word Information:\n",
      "Word: Tots | Lemma: tot | Part of Speech: DET | Syntactic Dependency: det | Head: els \n",
      "\n",
      "Word: els | Lemma: el | Part of Speech: DET | Syntactic Dependency: det | Head: éssers \n",
      "\n",
      "Word: éssers | Lemma: ésser | Part of Speech: NOUN | Syntactic Dependency: nsubj | Head: neixen \n",
      "\n",
      "Word: humans | Lemma: humà | Part of Speech: ADJ | Syntactic Dependency: amod | Head: éssers \n",
      "\n",
      "Word: neixen | Lemma: neixar | Part of Speech: VERB | Syntactic Dependency: ROOT | Head: neixen \n",
      "\n",
      "Word: lliures | Lemma: lliure | Part of Speech: ADJ | Syntactic Dependency: obj | Head: neixen \n",
      "\n",
      "Word: i | Lemma: i | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: iguals \n",
      "\n",
      "Word: iguals | Lemma: igual | Part of Speech: ADJ | Syntactic Dependency: conj | Head: lliures \n",
      "\n",
      "Word: en | Lemma: en | Part of Speech: ADP | Syntactic Dependency: case | Head: dignitat \n",
      "\n",
      "Word: dignitat | Lemma: dignitat | Part of Speech: NOUN | Syntactic Dependency: nmod | Head: lliures \n",
      "\n",
      "Word: i | Lemma: i | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: drets \n",
      "\n",
      "Word: drets | Lemma: dret | Part of Speech: NOUN | Syntactic Dependency: conj | Head: dignitat \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Catalan sentence syntax analysis\n",
    "print('- CATALAN Syntax -')\n",
    "print('Noun Phrases:', [chunk.text for chunk in ca_doc.noun_chunks])\n",
    "print('Verbs:', [token.lemma_ for token in ca_doc if token.pos_ == 'VERB'])\n",
    "print('Subjects:', [token.text for token in ca_doc if token.dep_ == 'nsubj'])\n",
    "print('Adjectives:', [token.text for token in ca_doc if token.pos_ == 'ADJ'])\n",
    "print('Prepositions:', [token.text for token in ca_doc if token.pos_ == 'ADP'])\n",
    "print('Conjunctions:', [token.text for token in ca_doc if token.pos_ == 'CCONJ'])\n",
    "print('+ Each word Information:')\n",
    "for token in ca_doc:\n",
    "\tprint(f'Word: {token.text} | Lemma: {token.lemma_} | Part of Speech: {token.pos_} | Syntactic Dependency: {token.dep_} | Head: {token.head.text} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- SPANISH Syntax -\n",
      "Noun Phrases: ['Todos los seres humanos', 'dignidad', 'derechos']\n",
      "Verbs: ['nacer']\n",
      "Subjects: ['seres']\n",
      "Adjectives: ['humanos', 'libres', 'iguales']\n",
      "Prepositions: ['en']\n",
      "Conjunctions: ['e', 'y']\n",
      "+ Each word Information:\n",
      "Word: Todos | Lemma: todo | Part of Speech: DET | Syntactic Dependency: det | Head: los \n",
      "\n",
      "Word: los | Lemma: el | Part of Speech: DET | Syntactic Dependency: det | Head: seres \n",
      "\n",
      "Word: seres | Lemma: ser | Part of Speech: NOUN | Syntactic Dependency: nsubj | Head: nacen \n",
      "\n",
      "Word: humanos | Lemma: humano | Part of Speech: ADJ | Syntactic Dependency: amod | Head: seres \n",
      "\n",
      "Word: nacen | Lemma: nacer | Part of Speech: VERB | Syntactic Dependency: ROOT | Head: nacen \n",
      "\n",
      "Word: libres | Lemma: libre | Part of Speech: ADJ | Syntactic Dependency: obj | Head: nacen \n",
      "\n",
      "Word: e | Lemma: e | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: iguales \n",
      "\n",
      "Word: iguales | Lemma: igual | Part of Speech: ADJ | Syntactic Dependency: conj | Head: libres \n",
      "\n",
      "Word: en | Lemma: en | Part of Speech: ADP | Syntactic Dependency: case | Head: dignidad \n",
      "\n",
      "Word: dignidad | Lemma: dignidad | Part of Speech: NOUN | Syntactic Dependency: nmod | Head: libres \n",
      "\n",
      "Word: y | Lemma: y | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: derechos \n",
      "\n",
      "Word: derechos | Lemma: derecho | Part of Speech: NOUN | Syntactic Dependency: conj | Head: libres \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spanish sencence syntax analysis\n",
    "print('- SPANISH Syntax -')\n",
    "print('Noun Phrases:', [chunk.text for chunk in es_doc.noun_chunks])\n",
    "print('Verbs:', [token.lemma_ for token in es_doc if token.pos_ == 'VERB'])\n",
    "print('Subjects:', [token.text for token in es_doc if token.dep_ == 'nsubj'])\n",
    "print('Adjectives:', [token.text for token in es_doc if token.pos_ == 'ADJ'])\n",
    "print('Prepositions:', [token.text for token in es_doc if token.pos_ == 'ADP'])\n",
    "print('Conjunctions:', [token.text for token in es_doc if token.pos_ == 'CCONJ'])\n",
    "print('+ Each word Information:')\n",
    "for token in es_doc:\n",
    "\tprint(f'Word: {token.text} | Lemma: {token.lemma_} | Part of Speech: {token.pos_} | Syntactic Dependency: {token.dep_} | Head: {token.head.text} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Recuperación de información\n",
    "\n",
    "Cargue el artículo de la wikipedia sobre Europa ([https://es.wikipedia.org/wiki/Europa](https://es.wikipedia.org/wiki/Europa)) en una lista de frases y recupera la información siguiente, buscando las frases más parecidas.\n",
    "\n",
    "- ¿Cuándo se gestó el concepto de Europa?\n",
    "\n",
    "- ¿Cuál es la especie humana autóctona de Europa?\n",
    "\n",
    "- ¿Cuándo se formaron los estados actuales de Europa?\n",
    "\n",
    "- ¿Qué clima tiene Europa?\n",
    "\n",
    "¿Todas las preguntas obtienen una respuesta adecuada? ¿Hay preguntas que conviene formular de otra forma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[Repository Link](https://github.com/CharlyMech/IEDIB_CEIA_2024-25/blob/main/Modelos%20de%20Inteligencia%20Artificial/Bloque%205/Actividades/5.1/tarea_5_Carlos_SanchezRecio.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
