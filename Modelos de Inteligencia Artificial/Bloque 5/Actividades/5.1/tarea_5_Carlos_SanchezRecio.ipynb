{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tarea de esta entrega trabajará cuatro aplicaciones de procesamiento del lenguaje general: clasificación de texto, generación de texto, análisis sintáctico y recuperación de información (_Information Retrieval_) . \n",
    "\n",
    "Las funciones que necesitará las puede obtener del código del capítulo de NLP del libro AIMA. Deberá mirar qué dependencias tienen respecto a otros archivos, incluir el código que sea necesario o importarlo de otros módulos.\n",
    "\n",
    "[https://github.com/aimacode/aima-python/blob/master/nlp_apps.ipynb](https://github.com/aimacode/aima-python/blob/master/nlp_apps.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clasificación de texto según el autor\n",
    "\n",
    "Construya dos modelos de diferentes autores: Josep Carner y Miquel dels Sants Oliver. Para eso, puede usar sus obras disponibles en el Proyecto Gutenberg. Por ejemplo, de Carner tome la traducción de los cuentos de Mark Twain. Después, clasifica frases en el estilo de cada uno que muestren cómo su modelo las identifica correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aima_module.utils import open_data\n",
    "from aima_module.text import words, UnigramWordModel\n",
    "from aima_module.learning import NaiveBayesLearner\n",
    "\n",
    "def recognize_author(text, nbs):\n",
    "   return nbs(words(text.lower()))\n",
    "\n",
    "hostel = open_data('CA-Text/bolla_hostel.txt').read()\n",
    "wordseq_hostel = words(hostel)\n",
    "p_miquel = UnigramWordModel(wordseq_hostel, 5)\n",
    "\n",
    "adventures = open_data('CA-Text/tom_sawyer_adventures.txt').read()\n",
    "wordseq_adventures = words(adventures)\n",
    "p_josep = UnigramWordModel(wordseq_adventures, 5)\n",
    "\n",
    "\n",
    "nbs = NaiveBayesLearner({('Miquel', 1): p_miquel, ('Josep', 1): p_josep}, simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the \"L'hostal de la Bolla\" [line 172]\n",
    "recognize_author('de la familia, entre sacs de bessó i senalles de llegum. La botiga,', nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From \"The Adventures of Tom Sawyer\" [line 4149]\n",
    "recognize_author('resta de cent yardes. Nedava quartejant per amunt el corrent, però', nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Author's quotes prompt](./authors_phrases_prompt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Miquel dels Sants Oliver\n",
    "recognize_author('La joventut, en el sentit màgic, potser no ha mai existit i potser no és sinó un equador convencional entre la il·lusió i el record.', nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Josep Carner\n",
    "recognize_author('Una mica d\\'amistat fins a morir diu que dura. Vés, amor, metzina impura; vull la mel, vull el brossat d\\'una mica d\\'amistat.', nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como comentario a cerca del resultado, se puede observar que no es del todo preciso en la clasificación. Haciendo uso de la actividad de mi compañero David Ramírez ([enlace a su tarea](https://github.com/davidzz-code/IEDIB_2024_2025/blob/main/02%20Modelos%20IA/T5%20NLP/tarea_4_David_Ramirez_Ruiz.ipynb)), voy a probar con las frases que ha utilizado él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miquel'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Miquel dels Sants Oliver\n",
    "recognize_author('Els carrers, encara humits, semblaven desertar de la nit', nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Josep'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quote from Josep Carner\n",
    "recognize_author('Amb un gest majestuós em fità un instant', nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que en este caso, el clasificador si que los diferencia correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generación de texto\n",
    "\n",
    "Construya modelos n-gram con n=1, n=3, n=5 y=7 a partir de un texto elegido por usted. Puede ser una obra del Proyecto Gutenberg o una noticia de prensa, por ejemplo. Observe como medida que aumenta el número de palabras que se han tenido en cuenta la verosimilitud del texto generado es mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análisis sintáctico\n",
    "\n",
    "Aplica las herramientas de alguna librería Python para analizar sintácticamente la siguiente oración:\n",
    "\n",
    "- (ES): _Todos los seres humanos nacen libres e iguales en dignidad y derechos._\n",
    "\n",
    "- (CA): _Tots els éssers humans neixen lliures i iguals en dignitat i drets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_sm-3.8.0/ca_core_news_sm-3.8.0-py3-none-any.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ca_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ca_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "es_nlp = spacy.load('es_core_news_sm')\n",
    "ca_nlp = spacy.load('ca_core_news_sm')\n",
    "\n",
    "es_sentence = 'Todos los seres humanos nacen libres e iguales en dignidad y derechos'\n",
    "ca_sentence = 'Tots els éssers humans neixen lliures i iguals en dignitat i drets'\n",
    "\n",
    "es_doc = es_nlp(es_sentence)\n",
    "ca_doc = ca_nlp(ca_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- CATALAN Syntax -\n",
      "Noun Phrases: ['Tots els éssers humans', 'dignitat i drets']\n",
      "Verbs: ['neixar']\n",
      "Subjects: ['éssers']\n",
      "Adjectives: ['humans', 'lliures', 'iguals']\n",
      "Prepositions: ['en']\n",
      "Conjunctions: ['i', 'i']\n",
      "+ Each word Information:\n",
      "Word: Tots | Lemma: tot | Part of Speech: DET | Syntactic Dependency: det | Head: els \n",
      "\n",
      "Word: els | Lemma: el | Part of Speech: DET | Syntactic Dependency: det | Head: éssers \n",
      "\n",
      "Word: éssers | Lemma: ésser | Part of Speech: NOUN | Syntactic Dependency: nsubj | Head: neixen \n",
      "\n",
      "Word: humans | Lemma: humà | Part of Speech: ADJ | Syntactic Dependency: amod | Head: éssers \n",
      "\n",
      "Word: neixen | Lemma: neixar | Part of Speech: VERB | Syntactic Dependency: ROOT | Head: neixen \n",
      "\n",
      "Word: lliures | Lemma: lliure | Part of Speech: ADJ | Syntactic Dependency: obj | Head: neixen \n",
      "\n",
      "Word: i | Lemma: i | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: iguals \n",
      "\n",
      "Word: iguals | Lemma: igual | Part of Speech: ADJ | Syntactic Dependency: conj | Head: lliures \n",
      "\n",
      "Word: en | Lemma: en | Part of Speech: ADP | Syntactic Dependency: case | Head: dignitat \n",
      "\n",
      "Word: dignitat | Lemma: dignitat | Part of Speech: NOUN | Syntactic Dependency: nmod | Head: lliures \n",
      "\n",
      "Word: i | Lemma: i | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: drets \n",
      "\n",
      "Word: drets | Lemma: dret | Part of Speech: NOUN | Syntactic Dependency: conj | Head: dignitat \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Catalan sentence syntax analysis\n",
    "print('- CATALAN Syntax -')\n",
    "print('Noun Phrases:', [chunk.text for chunk in ca_doc.noun_chunks])\n",
    "print('Verbs:', [token.lemma_ for token in ca_doc if token.pos_ == 'VERB'])\n",
    "print('Subjects:', [token.text for token in ca_doc if token.dep_ == 'nsubj'])\n",
    "print('Adjectives:', [token.text for token in ca_doc if token.pos_ == 'ADJ'])\n",
    "print('Prepositions:', [token.text for token in ca_doc if token.pos_ == 'ADP'])\n",
    "print('Conjunctions:', [token.text for token in ca_doc if token.pos_ == 'CCONJ'])\n",
    "print('+ Each word Information:')\n",
    "for token in ca_doc:\n",
    "\tprint(f'Word: {token.text} | Lemma: {token.lemma_} | Part of Speech: {token.pos_} | Syntactic Dependency: {token.dep_} | Head: {token.head.text} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- SPANISH Syntax -\n",
      "Noun Phrases: ['Todos los seres humanos', 'dignidad', 'derechos']\n",
      "Verbs: ['nacer']\n",
      "Subjects: ['seres']\n",
      "Adjectives: ['humanos', 'libres', 'iguales']\n",
      "Prepositions: ['en']\n",
      "Conjunctions: ['e', 'y']\n",
      "+ Each word Information:\n",
      "Word: Todos | Lemma: todo | Part of Speech: DET | Syntactic Dependency: det | Head: los \n",
      "\n",
      "Word: los | Lemma: el | Part of Speech: DET | Syntactic Dependency: det | Head: seres \n",
      "\n",
      "Word: seres | Lemma: ser | Part of Speech: NOUN | Syntactic Dependency: nsubj | Head: nacen \n",
      "\n",
      "Word: humanos | Lemma: humano | Part of Speech: ADJ | Syntactic Dependency: amod | Head: seres \n",
      "\n",
      "Word: nacen | Lemma: nacer | Part of Speech: VERB | Syntactic Dependency: ROOT | Head: nacen \n",
      "\n",
      "Word: libres | Lemma: libre | Part of Speech: ADJ | Syntactic Dependency: obj | Head: nacen \n",
      "\n",
      "Word: e | Lemma: e | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: iguales \n",
      "\n",
      "Word: iguales | Lemma: igual | Part of Speech: ADJ | Syntactic Dependency: conj | Head: libres \n",
      "\n",
      "Word: en | Lemma: en | Part of Speech: ADP | Syntactic Dependency: case | Head: dignidad \n",
      "\n",
      "Word: dignidad | Lemma: dignidad | Part of Speech: NOUN | Syntactic Dependency: nmod | Head: libres \n",
      "\n",
      "Word: y | Lemma: y | Part of Speech: CCONJ | Syntactic Dependency: cc | Head: derechos \n",
      "\n",
      "Word: derechos | Lemma: derecho | Part of Speech: NOUN | Syntactic Dependency: conj | Head: libres \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spanish sencence syntax analysis\n",
    "print('- SPANISH Syntax -')\n",
    "print('Noun Phrases:', [chunk.text for chunk in es_doc.noun_chunks])\n",
    "print('Verbs:', [token.lemma_ for token in es_doc if token.pos_ == 'VERB'])\n",
    "print('Subjects:', [token.text for token in es_doc if token.dep_ == 'nsubj'])\n",
    "print('Adjectives:', [token.text for token in es_doc if token.pos_ == 'ADJ'])\n",
    "print('Prepositions:', [token.text for token in es_doc if token.pos_ == 'ADP'])\n",
    "print('Conjunctions:', [token.text for token in es_doc if token.pos_ == 'CCONJ'])\n",
    "print('+ Each word Information:')\n",
    "for token in es_doc:\n",
    "\tprint(f'Word: {token.text} | Lemma: {token.lemma_} | Part of Speech: {token.pos_} | Syntactic Dependency: {token.dep_} | Head: {token.head.text} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Recuperación de información\n",
    "\n",
    "Cargue el artículo de la wikipedia sobre Europa ([https://es.wikipedia.org/wiki/Europa](https://es.wikipedia.org/wiki/Europa)) en una lista de frases y recupera la información siguiente, buscando las frases más parecidas.\n",
    "\n",
    "- ¿Cuándo se gestó el concepto de Europa?\n",
    "\n",
    "- ¿Cuál es la especie humana autóctona de Europa?\n",
    "\n",
    "- ¿Cuándo se formaron los estados actuales de Europa?\n",
    "\n",
    "- ¿Qué clima tiene Europa?\n",
    "\n",
    "¿Todas las preguntas obtienen una respuesta adecuada? ¿Hay preguntas que conviene formular de otra forma?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
